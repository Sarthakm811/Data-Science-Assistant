"""Report Generation Module"""
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import json

class ReportGenerator:
    def __init__(self, df, analysis_results=None):
        self.df = df
        self.analysis_results = analysis_results or {}
        self.timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def generate_markdown_report(self):
        """Generate markdown report"""
        report = f"""
# Data Science Analysis Report
**Generated:** {self.timestamp}

## Dataset Overview
- **Shape:** {self.df.shape[0]} rows Ã— {self.df.shape[1]} columns
- **Memory Usage:** {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB
- **Columns:** {', '.join(self.df.columns)}

## Data Types
```
{self.df.dtypes}
```

## Missing Values
```
{self.df.isnull().sum()}
```

## Descriptive Statistics
```
{self.df.describe()}
```

## Data Quality
- **Duplicates:** {self.df.duplicated().sum()}
- **Missing Values:** {self.df.isnull().sum().sum()}
- **Completeness:** {(1 - self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100:.2f}%

## Analysis Results
{json.dumps(self.analysis_results, indent=2, default=str)}

---
*Report generated by Data Science Assistant*
"""
        return report
    
    def generate_python_code(self):
        """Generate reproducible Python code"""
        code = '''
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Load data
df = pd.read_csv('your_data.csv')

# Data exploration
print(df.head())
print(df.info())
print(df.describe())

# Data cleaning
df = df.dropna()
df = df.drop_duplicates()

# Feature scaling
scaler = StandardScaler()
numeric_cols = df.select_dtypes(include=[np.number]).columns
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# Train-test split
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model training
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluation
score = model.score(X_test, y_test)
print(f"Model Accuracy: {score:.4f}")
'''
        return code
    
    def export_to_json(self):
        """Export analysis to JSON"""
        export_data = {
            'timestamp': self.timestamp,
            'dataset_shape': self.df.shape,
            'columns': list(self.df.columns),
            'dtypes': self.df.dtypes.astype(str).to_dict(),
            'missing_values': self.df.isnull().sum().to_dict(),
            'statistics': self.df.describe().to_dict(),
            'analysis_results': self.analysis_results
        }
        return json.dumps(export_data, indent=2, default=str)
    
    def export_to_csv(self):
        """Export dataframe to CSV"""
        return self.df.to_csv(index=False)
    
    def export_to_excel(self):
        """Export to Excel with multiple sheets"""
        output = {}
        output['Data'] = self.df
        output['Statistics'] = self.df.describe()
        output['Data Types'] = pd.DataFrame({
            'Column': self.df.columns,
            'Type': self.df.dtypes
        })
        return output
    
    def create_summary_stats(self):
        """Create summary statistics table"""
        summary = pd.DataFrame({
            'Column': self.df.columns,
            'Type': self.df.dtypes,
            'Non-Null': self.df.count(),
            'Null': self.df.isnull().sum(),
            'Unique': self.df.nunique()
        })
        return summary
